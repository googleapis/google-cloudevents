{
  "$id": "https://googleapis.github.io/google-cloudevents/jsonschema/google/events/cloud/video/transcoder/v1/JobTemplateEventData.json",
  "name": "JobTemplateEventData",
  "examples": [],
  "package": "google.events.cloud.video.transcoder.v1",
  "datatype": "google.events.cloud.video.transcoder.v1.JobTemplateEventData",
  "cloudeventTypes": [
    "google.cloud.video.transcoder.jobTemplate.v1.created",
    "google.cloud.video.transcoder.jobTemplate.v1.deleted"
  ],
  "product": "Transcoder",
  "$schema": "http://json-schema.org/draft-04/schema#",
  "$ref": "#/definitions/JobTemplateEventData",
  "definitions": {
    "JobTemplateEventData": {
      "properties": {
        "payload": {
          "$ref": "#/definitions/JobTemplate",
          "additionalProperties": true,
          "description": "Optional. The JobTemplate event payload. Unset for deletion events."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Job Template Event Data",
      "description": "The data within all JobTemplate events."
    },
    "AdBreak": {
      "properties": {
        "startTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Start time in seconds for the ad break, relative to the output file timeline. The default is `0s`.",
          "format": "regex"
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Ad Break",
      "description": "Ad break."
    },
    "AudioStream": {
      "properties": {
        "codec": {
          "type": "string",
          "description": "The codec for this audio stream. The default is `aac`. Supported audio codecs: - `aac` - `aac-he` - `aac-he-v2` - `mp3` - `ac3` - `eac3`"
        },
        "bitrateBps": {
          "type": "integer",
          "description": "Required. Audio bitrate in bits per second. Must be between 1 and 10,000,000."
        },
        "channelCount": {
          "type": "integer",
          "description": "Number of audio channels. Must be between 1 and 6. The default is 2."
        },
        "channelLayout": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "A list of channel names specifying layout of the audio channels. This only affects the metadata embedded in the container headers, if supported by the specified format. The default is `[\"fl\", \"fr\"]`. Supported channel names: - `fl` - Front left channel - `fr` - Front right channel - `sl` - Side left channel - `sr` - Side right channel - `fc` - Front center channel - `lfe` - Low frequency"
        },
        "mapping": {
          "items": {
            "$ref": "#/definitions/AudioMapping"
          },
          "type": "array",
          "description": "The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`."
        },
        "sampleRateHertz": {
          "type": "integer",
          "description": "The audio sample rate in Hertz. The default is 48000 Hertz."
        },
        "languageCode": {
          "type": "string",
          "description": "The BCP-47 language code, such as `en-US` or `sr-Latn`. For more information, see https://www.unicode.org/reports/tr35/#Unicode_locale_identifier. Not supported in MP4 files."
        },
        "displayName": {
          "type": "string",
          "description": "The name for this particular audio stream that will be added to the HLS/DASH manifest. Not supported in MP4 files."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Audio Stream",
      "description": "Audio stream resource."
    },
    "AudioMapping": {
      "properties": {
        "atomKey": {
          "type": "string",
          "description": "Required. The `EditAtom.key` that references the atom with audio inputs in the `Job.edit_list`."
        },
        "inputKey": {
          "type": "string",
          "description": "Required. The `Input.key` that identifies the input file."
        },
        "inputTrack": {
          "type": "integer",
          "description": "Required. The zero-based index of the track in the input file."
        },
        "inputChannel": {
          "type": "integer",
          "description": "Required. The zero-based index of the channel in the input audio stream."
        },
        "outputChannel": {
          "type": "integer",
          "description": "Required. The zero-based index of the channel in the output audio stream."
        },
        "gainDb": {
          "type": "number",
          "description": "Audio volume control in dB. Negative values decrease volume, positive values increase. The default is 0."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Audio Mapping",
      "description": "The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`."
    },
    "EditAtom": {
      "properties": {
        "key": {
          "type": "string",
          "description": "A unique key for this atom. Must be specified when using advanced mapping."
        },
        "inputs": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "List of `Input.key`s identifying files that should be used in this atom. The listed `inputs` must have the same timeline."
        },
        "endTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "End time in seconds for the atom, relative to the input file timeline. When `end_time_offset` is not specified, the `inputs` are used until the end of the atom.",
          "format": "regex"
        },
        "startTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Start time in seconds for the atom, relative to the input file timeline. The default is `0s`.",
          "format": "regex"
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Edit Atom",
      "description": "Edit atom."
    },
    "ElementaryStream": {
      "properties": {
        "key": {
          "type": "string",
          "description": "A unique key for this elementary stream."
        },
        "videoStream": {
          "$ref": "#/definitions/VideoStream",
          "additionalProperties": true,
          "description": "Encoding of a video stream."
        },
        "audioStream": {
          "$ref": "#/definitions/AudioStream",
          "additionalProperties": true,
          "description": "Encoding of an audio stream."
        },
        "textStream": {
          "$ref": "#/definitions/TextStream",
          "additionalProperties": true,
          "description": "Encoding of a text stream. For example, closed captions or subtitles."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Elementary Stream",
      "description": "Encoding of an input file such as an audio, video, or text track. Elementary streams must be packaged before mapping and sharing between different output formats."
    },
    "Input": {
      "properties": {
        "key": {
          "type": "string",
          "description": "A unique key for this input. Must be specified when using advanced mapping and edit lists."
        },
        "uri": {
          "type": "string",
          "description": "URI of the media. Input files must be at least 5 seconds in duration and stored in Cloud Storage (for example, `gs://bucket/inputs/file.mp4`). If empty, the value is populated from `Job.input_uri`. See [Supported input and output formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats)."
        },
        "preprocessingConfig": {
          "$ref": "#/definitions/PreprocessingConfig",
          "additionalProperties": true,
          "description": "Preprocessing configurations."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Input",
      "description": "Input asset."
    },
    "JobConfig": {
      "properties": {
        "inputs": {
          "items": {
            "$ref": "#/definitions/Input"
          },
          "type": "array",
          "description": "List of input assets stored in Cloud Storage."
        },
        "editList": {
          "items": {
            "$ref": "#/definitions/EditAtom"
          },
          "type": "array",
          "description": "List of `Edit atom`s. Defines the ultimate timeline of the resulting file or manifest."
        },
        "elementaryStreams": {
          "items": {
            "$ref": "#/definitions/ElementaryStream"
          },
          "type": "array",
          "description": "List of elementary streams."
        },
        "muxStreams": {
          "items": {
            "$ref": "#/definitions/MuxStream"
          },
          "type": "array",
          "description": "List of multiplexing settings for output streams."
        },
        "manifests": {
          "items": {
            "$ref": "#/definitions/Manifest"
          },
          "type": "array",
          "description": "List of output manifests."
        },
        "output": {
          "$ref": "#/definitions/Output",
          "additionalProperties": true,
          "description": "Output configuration."
        },
        "adBreaks": {
          "items": {
            "$ref": "#/definitions/AdBreak"
          },
          "type": "array",
          "description": "List of ad breaks. Specifies where to insert ad break tags in the output manifests."
        },
        "pubsubDestination": {
          "$ref": "#/definitions/PubsubDestination",
          "additionalProperties": true,
          "description": "Destination on Pub/Sub."
        },
        "spriteSheets": {
          "items": {
            "$ref": "#/definitions/SpriteSheet"
          },
          "type": "array",
          "description": "List of output sprite sheets. Spritesheets require at least one VideoStream in the Jobconfig."
        },
        "overlays": {
          "items": {
            "$ref": "#/definitions/Overlay"
          },
          "type": "array",
          "description": "List of overlays on the output video, in descending Z-order."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Job Config",
      "description": "Job configuration"
    },
    "JobTemplate": {
      "properties": {
        "name": {
          "type": "string",
          "description": "The resource name of the job template. Format: `projects/{project_number}/locations/{location}/jobTemplates/{job_template}`"
        },
        "config": {
          "$ref": "#/definitions/JobConfig",
          "additionalProperties": true,
          "description": "The configuration for this template."
        },
        "labels": {
          "additionalProperties": {
            "type": "string"
          },
          "type": "object",
          "description": "The labels associated with this job template. You can use these to organize and group your job templates."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Job Template",
      "description": "Transcoding job template resource."
    },
    "Manifest": {
      "properties": {
        "fileName": {
          "type": "string",
          "description": "The name of the generated file. The default is `manifest` with the extension suffix corresponding to the `Manifest.type`."
        },
        "type": {
          "enum": [
            "MANIFEST_TYPE_UNSPECIFIED",
            0,
            "HLS",
            1,
            "DASH",
            2
          ],
          "oneOf": [
            {
              "type": "string"
            },
            {
              "type": "integer"
            }
          ],
          "title": "Manifest Type",
          "description": "The manifest type, which corresponds to the adaptive streaming format used."
        },
        "muxStreams": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "Required. List of user given `MuxStream.key`s that should appear in this manifest. When `Manifest.type` is `HLS`, a media manifest with name `MuxStream.key` and `.m3u8` extension is generated for each element of the `Manifest.mux_streams`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Manifest",
      "description": "Manifest configuration."
    },
    "MuxStream": {
      "properties": {
        "key": {
          "type": "string",
          "description": "A unique key for this multiplexed stream. HLS media manifests will be named `MuxStream.key` with the `.m3u8` extension suffix."
        },
        "fileName": {
          "type": "string",
          "description": "The name of the generated file. The default is `MuxStream.key` with the extension suffix corresponding to the `MuxStream.container`. Individual segments also have an incremental 10-digit zero-padded suffix starting from 0 before the extension, such as `mux_stream0000000123.ts`."
        },
        "container": {
          "type": "string",
          "description": "The container format. The default is `mp4` Supported container formats: - `ts` - `fmp4`- the corresponding file extension is `.m4s` - `mp4` - `vtt` See also: [Supported input and output formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats)"
        },
        "elementaryStreams": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "List of `ElementaryStream.key`s multiplexed in this stream."
        },
        "segmentSettings": {
          "$ref": "#/definitions/SegmentSettings",
          "additionalProperties": true,
          "description": "Segment settings for `ts`, `fmp4` and `vtt`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Mux Stream",
      "description": "Multiplexing settings for output stream."
    },
    "Output": {
      "properties": {
        "uri": {
          "type": "string",
          "description": "URI for the output file(s). For example, `gs://my-bucket/outputs/`. If empty, the value is populated from `Job.output_uri`. See [Supported input and output formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats)."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Output",
      "description": "Location of output file(s) in a Cloud Storage bucket."
    },
    "Overlay": {
      "properties": {
        "image": {
          "$ref": "#/definitions/Image",
          "additionalProperties": true,
          "description": "Image overlay."
        },
        "animations": {
          "items": {
            "$ref": "#/definitions/Animation"
          },
          "type": "array",
          "description": "List of Animations. The list should be chronological, without any time overlap."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Overlay",
      "description": "Overlay configuration."
    },
    "Animation": {
      "properties": {
        "animationStatic": {
          "$ref": "#/definitions/AnimationStatic",
          "additionalProperties": true,
          "description": "Display static overlay object."
        },
        "animationFade": {
          "$ref": "#/definitions/AnimationFade",
          "additionalProperties": true,
          "description": "Display overlay object with fade animation."
        },
        "animationEnd": {
          "$ref": "#/definitions/AnimationEnd",
          "additionalProperties": true,
          "description": "End previous animation."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Animation",
      "description": "Animation types."
    },
    "AnimationEnd": {
      "properties": {
        "startTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "The time to end overlay object, in seconds. Default: 0",
          "format": "regex"
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Animation End",
      "description": "End previous overlay animation from the video. Without AnimationEnd, the overlay object will keep the state of previous animation until the end of the video."
    },
    "AnimationFade": {
      "properties": {
        "fadeType": {
          "enum": [
            "FADE_TYPE_UNSPECIFIED",
            0,
            "FADE_IN",
            1,
            "FADE_OUT",
            2
          ],
          "oneOf": [
            {
              "type": "string"
            },
            {
              "type": "integer"
            }
          ],
          "title": "Fade Type",
          "description": "Fade type for the overlay: `FADE_IN` or `FADE_OUT`."
        },
        "xy": {
          "$ref": "#/definitions/NormalizedCoordinate",
          "additionalProperties": true,
          "description": "Normalized coordinates based on output video resolution. Valid values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay object. For example, use the x and y coordinates {0,0} to position the top-left corner of the overlay animation in the top-left corner of the output video."
        },
        "startTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "The time to start the fade animation, in seconds. Default: 0",
          "format": "regex"
        },
        "endTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "The time to end the fade animation, in seconds. Default: `start_time_offset` + 1s",
          "format": "regex"
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Animation Fade",
      "description": "Display overlay object with fade animation."
    },
    "AnimationStatic": {
      "properties": {
        "xy": {
          "$ref": "#/definitions/NormalizedCoordinate",
          "additionalProperties": true,
          "description": "Normalized coordinates based on output video resolution. Valid values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay object. For example, use the x and y coordinates {0,0} to position the top-left corner of the overlay animation in the top-left corner of the output video."
        },
        "startTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "The time to start displaying the overlay object, in seconds. Default: 0",
          "format": "regex"
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Animation Static",
      "description": "Display static overlay object."
    },
    "Image": {
      "properties": {
        "uri": {
          "type": "string",
          "description": "Required. URI of the image in Cloud Storage. For example, `gs://bucket/inputs/image.png`. Only PNG and JPEG images are supported."
        },
        "resolution": {
          "$ref": "#/definitions/NormalizedCoordinate",
          "additionalProperties": true,
          "description": "Normalized image resolution, based on output video resolution. Valid values: `0.0`–`1.0`. To respect the original image aspect ratio, set either `x` or `y` to `0.0`. To use the original image resolution, set both `x` and `y` to `0.0`."
        },
        "alpha": {
          "type": "number",
          "description": "Target image opacity. Valid values are from  `1.0` (solid, default) to `0.0` (transparent), exclusive. Set this to a value greater than `0.0`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Image",
      "description": "Overlaid image."
    },
    "NormalizedCoordinate": {
      "properties": {
        "x": {
          "type": "number",
          "description": "Normalized x coordinate."
        },
        "y": {
          "type": "number",
          "description": "Normalized y coordinate."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Normalized Coordinate",
      "description": "2D normalized coordinates. Default: `{0.0, 0.0}`"
    },
    "PreprocessingConfig": {
      "properties": {
        "color": {
          "$ref": "#/definitions/Color",
          "additionalProperties": true,
          "description": "Color preprocessing configuration."
        },
        "denoise": {
          "$ref": "#/definitions/Denoise",
          "additionalProperties": true,
          "description": "Denoise preprocessing configuration."
        },
        "deblock": {
          "$ref": "#/definitions/Deblock",
          "additionalProperties": true,
          "description": "Deblock preprocessing configuration."
        },
        "audio": {
          "$ref": "#/definitions/Audio",
          "additionalProperties": true,
          "description": "Audio preprocessing configuration."
        },
        "crop": {
          "$ref": "#/definitions/Crop",
          "additionalProperties": true,
          "description": "Specify the video cropping configuration."
        },
        "pad": {
          "$ref": "#/definitions/Pad",
          "additionalProperties": true,
          "description": "Specify the video pad filter configuration."
        },
        "deinterlace": {
          "$ref": "#/definitions/Deinterlace",
          "additionalProperties": true,
          "description": "Specify the video deinterlace configuration."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Preprocessing Config",
      "description": "Preprocessing configurations."
    },
    "Audio": {
      "properties": {
        "lufs": {
          "type": "number",
          "description": "Specify audio loudness normalization in loudness units relative to full scale (LUFS). Enter a value between -24 and 0 (the default), where: *   -24 is the Advanced Television Systems Committee (ATSC A/85) standard *   -23 is the EU R128 broadcast standard *   -19 is the prior standard for online mono audio *   -18 is the ReplayGain standard *   -16 is the prior standard for stereo audio *   -14 is the new online audio standard recommended by Spotify, as well     as Amazon Echo *   0 disables normalization"
        },
        "highBoost": {
          "type": "boolean",
          "description": "Enable boosting high frequency components. The default is `false`. **Note:** This field is not supported."
        },
        "lowBoost": {
          "type": "boolean",
          "description": "Enable boosting low frequency components. The default is `false`. **Note:** This field is not supported."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Audio",
      "description": "Audio preprocessing configuration."
    },
    "Color": {
      "properties": {
        "saturation": {
          "type": "number",
          "description": "Control color saturation of the video. Enter a value between -1 and 1, where -1 is fully desaturated and 1 is maximum saturation. 0 is no change. The default is 0."
        },
        "contrast": {
          "type": "number",
          "description": "Control black and white contrast of the video. Enter a value between -1 and 1, where -1 is minimum contrast and 1 is maximum contrast. 0 is no change. The default is 0."
        },
        "brightness": {
          "type": "number",
          "description": "Control brightness of the video. Enter a value between -1 and 1, where -1 is minimum brightness and 1 is maximum brightness. 0 is no change. The default is 0."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Color",
      "description": "Color preprocessing configuration. **Note:** This configuration is not supported."
    },
    "Crop": {
      "properties": {
        "topPixels": {
          "type": "integer",
          "description": "The number of pixels to crop from the top. The default is 0."
        },
        "bottomPixels": {
          "type": "integer",
          "description": "The number of pixels to crop from the bottom. The default is 0."
        },
        "leftPixels": {
          "type": "integer",
          "description": "The number of pixels to crop from the left. The default is 0."
        },
        "rightPixels": {
          "type": "integer",
          "description": "The number of pixels to crop from the right. The default is 0."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Crop",
      "description": "Video cropping configuration for the input video. The cropped input video is scaled to match the output resolution."
    },
    "Deblock": {
      "properties": {
        "strength": {
          "type": "number",
          "description": "Set strength of the deblocker. Enter a value between 0 and 1. The higher the value, the stronger the block removal. 0 is no deblocking. The default is 0."
        },
        "enabled": {
          "type": "boolean",
          "description": "Enable deblocker. The default is `false`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Deblock",
      "description": "Deblock preprocessing configuration. **Note:** This configuration is not supported."
    },
    "Deinterlace": {
      "properties": {
        "yadif": {
          "$ref": "#/definitions/YadifConfig",
          "additionalProperties": true,
          "description": "Specifies the Yet Another Deinterlacing Filter Configuration."
        },
        "bwdif": {
          "$ref": "#/definitions/BwdifConfig",
          "additionalProperties": true,
          "description": "Specifies the Bob Weaver Deinterlacing Filter Configuration."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Deinterlace",
      "description": "Deinterlace configuration for input video."
    },
    "BwdifConfig": {
      "properties": {
        "mode": {
          "type": "string",
          "description": "Specifies the deinterlacing mode to adopt. The default is `send_frame`. Supported values: - `send_frame`: Output one frame for each frame - `send_field`: Output one frame for each field"
        },
        "parity": {
          "type": "string",
          "description": "The picture field parity assumed for the input interlaced video. The default is `auto`. Supported values: - `tff`: Assume the top field is first - `bff`: Assume the bottom field is first - `auto`: Enable automatic detection of field parity"
        },
        "deinterlaceAllFrames": {
          "type": "boolean",
          "description": "Deinterlace all frames rather than just the frames identified as interlaced. The default is `false`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Bwdif Config",
      "description": "Bob Weaver Deinterlacing Filter Configuration."
    },
    "YadifConfig": {
      "properties": {
        "mode": {
          "type": "string",
          "description": "Specifies the deinterlacing mode to adopt. The default is `send_frame`. Supported values: - `send_frame`: Output one frame for each frame - `send_field`: Output one frame for each field"
        },
        "disableSpatialInterlacing": {
          "type": "boolean",
          "description": "Disable spacial interlacing. The default is `false`."
        },
        "parity": {
          "type": "string",
          "description": "The picture field parity assumed for the input interlaced video. The default is `auto`. Supported values: - `tff`: Assume the top field is first - `bff`: Assume the bottom field is first - `auto`: Enable automatic detection of field parity"
        },
        "deinterlaceAllFrames": {
          "type": "boolean",
          "description": "Deinterlace all frames rather than just the frames identified as interlaced. The default is `false`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Yadif Config",
      "description": "Yet Another Deinterlacing Filter Configuration."
    },
    "Denoise": {
      "properties": {
        "strength": {
          "type": "number",
          "description": "Set strength of the denoise. Enter a value between 0 and 1. The higher the value, the smoother the image. 0 is no denoising. The default is 0."
        },
        "tune": {
          "type": "string",
          "description": "Set the denoiser mode. The default is `standard`. Supported denoiser modes: - `standard` - `grain`"
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Denoise",
      "description": "Denoise preprocessing configuration. **Note:** This configuration is not supported."
    },
    "Pad": {
      "properties": {
        "topPixels": {
          "type": "integer",
          "description": "The number of pixels to add to the top. The default is 0."
        },
        "bottomPixels": {
          "type": "integer",
          "description": "The number of pixels to add to the bottom. The default is 0."
        },
        "leftPixels": {
          "type": "integer",
          "description": "The number of pixels to add to the left. The default is 0."
        },
        "rightPixels": {
          "type": "integer",
          "description": "The number of pixels to add to the right. The default is 0."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Pad",
      "description": "Pad filter configuration for the input video. The padded input video is scaled after padding with black to match the output resolution."
    },
    "PubsubDestination": {
      "properties": {
        "topic": {
          "type": "string",
          "description": "The name of the Pub/Sub topic to publish job completion notification to. For example: `projects/{project}/topics/{topic}`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Pubsub Destination",
      "description": "A Pub/Sub destination."
    },
    "SegmentSettings": {
      "properties": {
        "segmentDuration": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Duration of the segments in seconds. The default is `6.0s`. Note that `segmentDuration` must be greater than or equal to [`gopDuration`](#videostream), and `segmentDuration` must be divisible by [`gopDuration`](#videostream).",
          "format": "regex"
        },
        "individualSegments": {
          "type": "boolean",
          "description": "Required. Create an individual segment file. The default is `false`."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Segment Settings",
      "description": "Segment settings for `ts`, `fmp4` and `vtt`."
    },
    "SpriteSheet": {
      "properties": {
        "format": {
          "type": "string",
          "description": "Format type. The default is `jpeg`. Supported formats: - `jpeg`"
        },
        "filePrefix": {
          "type": "string",
          "description": "Required. File name prefix for the generated sprite sheets. Each sprite sheet has an incremental 10-digit zero-padded suffix starting from 0 before the extension, such as `sprite_sheet0000000123.jpeg`."
        },
        "spriteWidthPixels": {
          "type": "integer",
          "description": "Required. The width of sprite in pixels. Must be an even integer. To preserve the source aspect ratio, set the [SpriteSheet.sprite_width_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_width_pixels] field or the [SpriteSheet.sprite_height_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_height_pixels] field, but not both (the API will automatically calculate the missing field). For portrait videos that contain horizontal ASR and rotation metadata, provide the width, in pixels, per the horizontal ASR. The API calculates the height per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "spriteHeightPixels": {
          "type": "integer",
          "description": "Required. The height of sprite in pixels. Must be an even integer. To preserve the source aspect ratio, set the [SpriteSheet.sprite_height_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_height_pixels] field or the [SpriteSheet.sprite_width_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_width_pixels] field, but not both (the API will automatically calculate the missing field). For portrait videos that contain horizontal ASR and rotation metadata, provide the height, in pixels, per the horizontal ASR. The API calculates the width per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "columnCount": {
          "type": "integer",
          "description": "The maximum number of sprites per row in a sprite sheet. The default is 0, which indicates no maximum limit."
        },
        "rowCount": {
          "type": "integer",
          "description": "The maximum number of rows per sprite sheet. When the sprite sheet is full, a new sprite sheet is created. The default is 0, which indicates no maximum limit."
        },
        "startTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Start time in seconds, relative to the output file timeline. Determines the first sprite to pick. The default is `0s`.",
          "format": "regex"
        },
        "endTimeOffset": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "End time in seconds, relative to the output file timeline. When `end_time_offset` is not specified, the sprites are generated until the end of the output file.",
          "format": "regex"
        },
        "totalCount": {
          "type": "integer",
          "description": "Total number of sprites. Create the specified number of sprites distributed evenly across the timeline of the output media. The default is 100."
        },
        "interval": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Starting from `0s`, create sprites at regular intervals. Specify the interval value in seconds.",
          "format": "regex"
        },
        "quality": {
          "type": "integer",
          "description": "The quality of the generated sprite sheet. Enter a value between 1 and 100, where 1 is the lowest quality and 100 is the highest quality. The default is 100. A high quality value corresponds to a low image data compression ratio."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Sprite Sheet",
      "description": "Sprite sheet configuration."
    },
    "TextStream": {
      "properties": {
        "codec": {
          "type": "string",
          "description": "The codec for this text stream. The default is `webvtt`. Supported text codecs: - `srt` - `ttml` - `cea608` - `cea708` - `webvtt`"
        },
        "languageCode": {
          "type": "string",
          "description": "The BCP-47 language code, such as `en-US` or `sr-Latn`. For more information, see https://www.unicode.org/reports/tr35/#Unicode_locale_identifier. Not supported in MP4 files."
        },
        "mapping": {
          "items": {
            "$ref": "#/definitions/TextMapping"
          },
          "type": "array",
          "description": "The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`."
        },
        "displayName": {
          "type": "string",
          "description": "The name for this particular text stream that will be added to the HLS/DASH manifest. Not supported in MP4 files."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Text Stream",
      "description": "Encoding of a text stream. For example, closed captions or subtitles."
    },
    "TextMapping": {
      "properties": {
        "atomKey": {
          "type": "string",
          "description": "Required. The `EditAtom.key` that references atom with text inputs in the `Job.edit_list`."
        },
        "inputKey": {
          "type": "string",
          "description": "Required. The `Input.key` that identifies the input file."
        },
        "inputTrack": {
          "type": "integer",
          "description": "Required. The zero-based index of the track in the input file."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Text Mapping",
      "description": "The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`."
    },
    "VideoStream": {
      "properties": {
        "h264": {
          "$ref": "#/definitions/H264CodecSettings",
          "additionalProperties": true,
          "description": "H264 codec settings."
        },
        "h265": {
          "$ref": "#/definitions/H265CodecSettings",
          "additionalProperties": true,
          "description": "H265 codec settings."
        },
        "vp9": {
          "$ref": "#/definitions/Vp9CodecSettings",
          "additionalProperties": true,
          "description": "VP9 codec settings."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Video Stream",
      "description": "Video stream resource."
    },
    "H264CodecSettings": {
      "properties": {
        "widthPixels": {
          "type": "integer",
          "description": "The width of the video in pixels. Must be an even integer. When not specified, the width is adjusted to match the specified height and input aspect ratio. If both are omitted, the input width is used. For portrait videos that contain horizontal ASR and rotation metadata, provide the width, in pixels, per the horizontal ASR. The API calculates the height per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "heightPixels": {
          "type": "integer",
          "description": "The height of the video in pixels. Must be an even integer. When not specified, the height is adjusted to match the specified width and input aspect ratio. If both are omitted, the input height is used. For portrait videos that contain horizontal ASR and rotation metadata, provide the height, in pixels, per the horizontal ASR. The API calculates the width per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "frameRate": {
          "type": "number",
          "description": "Required. The target video frame rate in frames per second (FPS). Must be less than or equal to 120. Will default to the input frame rate if larger than the input frame rate. The API will generate an output FPS that is divisible by the input FPS, and smaller or equal to the target FPS. See [Calculating frame rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for more information."
        },
        "bitrateBps": {
          "type": "integer",
          "description": "Required. The video bitrate in bits per second. The minimum value is 1,000. The maximum value is 800,000,000."
        },
        "pixelFormat": {
          "type": "string",
          "description": "Pixel format to use. The default is `yuv420p`. Supported pixel formats: - `yuv420p` pixel format - `yuv422p` pixel format - `yuv444p` pixel format - `yuv420p10` 10-bit HDR pixel format - `yuv422p10` 10-bit HDR pixel format - `yuv444p10` 10-bit HDR pixel format - `yuv420p12` 12-bit HDR pixel format - `yuv422p12` 12-bit HDR pixel format - `yuv444p12` 12-bit HDR pixel format"
        },
        "rateControlMode": {
          "type": "string",
          "description": "Specify the `rate_control_mode`. The default is `vbr`. Supported rate control modes: - `vbr` - variable bitrate - `crf` - constant rate factor"
        },
        "crfLevel": {
          "type": "integer",
          "description": "Target CRF level. Must be between 10 and 36, where 10 is the highest quality and 36 is the most efficient compression. The default is 21."
        },
        "allowOpenGop": {
          "type": "boolean",
          "description": "Specifies whether an open Group of Pictures (GOP) structure should be allowed or not. The default is `false`."
        },
        "gopFrameCount": {
          "type": "integer",
          "description": "Select the GOP size based on the specified frame count. Must be greater than zero."
        },
        "gopDuration": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Select the GOP size based on the specified duration. The default is `3s`. Note that `gopDuration` must be less than or equal to [`segmentDuration`](#SegmentSettings), and [`segmentDuration`](#SegmentSettings) must be divisible by `gopDuration`.",
          "format": "regex"
        },
        "enableTwoPass": {
          "type": "boolean",
          "description": "Use two-pass encoding strategy to achieve better video quality. `VideoStream.rate_control_mode` must be `vbr`. The default is `false`."
        },
        "vbvSizeBits": {
          "type": "integer",
          "description": "Size of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to `VideoStream.bitrate_bps`."
        },
        "vbvFullnessBits": {
          "type": "integer",
          "description": "Initial fullness of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to 90% of `VideoStream.vbv_size_bits`."
        },
        "entropyCoder": {
          "type": "string",
          "description": "The entropy coder to use. The default is `cabac`. Supported entropy coders: - `cavlc` - `cabac`"
        },
        "bPyramid": {
          "type": "boolean",
          "description": "Allow B-pyramid for reference frame selection. This may not be supported on all decoders. The default is `false`."
        },
        "bFrameCount": {
          "type": "integer",
          "description": "The number of consecutive B-frames. Must be greater than or equal to zero. Must be less than `VideoStream.gop_frame_count` if set. The default is 0."
        },
        "aqStrength": {
          "type": "number",
          "description": "Specify the intensity of the adaptive quantizer (AQ). Must be between 0 and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A higher value equals a lower bitrate but smoother image. The default is 0."
        },
        "profile": {
          "type": "string",
          "description": "Enforces the specified codec profile. The following profiles are supported: *   `baseline` *   `main` *   `high` (default) The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune). Note that certain values for this field may cause the transcoder to override other fields you set in the `H264CodecSettings` message."
        },
        "tune": {
          "type": "string",
          "description": "Enforces the specified codec tune. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune). Note that certain values for this field may cause the transcoder to override other fields you set in the `H264CodecSettings` message."
        },
        "preset": {
          "type": "string",
          "description": "Enforces the specified codec preset. The default is `veryfast`. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Preset). Note that certain values for this field may cause the transcoder to override other fields you set in the `H264CodecSettings` message."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "H 264 Codec Settings",
      "description": "H264 codec settings."
    },
    "H265CodecSettings": {
      "properties": {
        "widthPixels": {
          "type": "integer",
          "description": "The width of the video in pixels. Must be an even integer. When not specified, the width is adjusted to match the specified height and input aspect ratio. If both are omitted, the input width is used. For portrait videos that contain horizontal ASR and rotation metadata, provide the width, in pixels, per the horizontal ASR. The API calculates the height per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "heightPixels": {
          "type": "integer",
          "description": "The height of the video in pixels. Must be an even integer. When not specified, the height is adjusted to match the specified width and input aspect ratio. If both are omitted, the input height is used. For portrait videos that contain horizontal ASR and rotation metadata, provide the height, in pixels, per the horizontal ASR. The API calculates the width per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "frameRate": {
          "type": "number",
          "description": "Required. The target video frame rate in frames per second (FPS). Must be less than or equal to 120. Will default to the input frame rate if larger than the input frame rate. The API will generate an output FPS that is divisible by the input FPS, and smaller or equal to the target FPS. See [Calculating frame rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for more information."
        },
        "bitrateBps": {
          "type": "integer",
          "description": "Required. The video bitrate in bits per second. The minimum value is 1,000. The maximum value is 800,000,000."
        },
        "pixelFormat": {
          "type": "string",
          "description": "Pixel format to use. The default is `yuv420p`. Supported pixel formats: - `yuv420p` pixel format - `yuv422p` pixel format - `yuv444p` pixel format - `yuv420p10` 10-bit HDR pixel format - `yuv422p10` 10-bit HDR pixel format - `yuv444p10` 10-bit HDR pixel format - `yuv420p12` 12-bit HDR pixel format - `yuv422p12` 12-bit HDR pixel format - `yuv444p12` 12-bit HDR pixel format"
        },
        "rateControlMode": {
          "type": "string",
          "description": "Specify the `rate_control_mode`. The default is `vbr`. Supported rate control modes: - `vbr` - variable bitrate - `crf` - constant rate factor"
        },
        "crfLevel": {
          "type": "integer",
          "description": "Target CRF level. Must be between 10 and 36, where 10 is the highest quality and 36 is the most efficient compression. The default is 21."
        },
        "allowOpenGop": {
          "type": "boolean",
          "description": "Specifies whether an open Group of Pictures (GOP) structure should be allowed or not. The default is `false`."
        },
        "gopFrameCount": {
          "type": "integer",
          "description": "Select the GOP size based on the specified frame count. Must be greater than zero."
        },
        "gopDuration": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Select the GOP size based on the specified duration. The default is `3s`. Note that `gopDuration` must be less than or equal to [`segmentDuration`](#SegmentSettings), and [`segmentDuration`](#SegmentSettings) must be divisible by `gopDuration`.",
          "format": "regex"
        },
        "enableTwoPass": {
          "type": "boolean",
          "description": "Use two-pass encoding strategy to achieve better video quality. `VideoStream.rate_control_mode` must be `vbr`. The default is `false`."
        },
        "vbvSizeBits": {
          "type": "integer",
          "description": "Size of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to `VideoStream.bitrate_bps`."
        },
        "vbvFullnessBits": {
          "type": "integer",
          "description": "Initial fullness of the Video Buffering Verifier (VBV) buffer in bits. Must be greater than zero. The default is equal to 90% of `VideoStream.vbv_size_bits`."
        },
        "bPyramid": {
          "type": "boolean",
          "description": "Allow B-pyramid for reference frame selection. This may not be supported on all decoders. The default is `false`."
        },
        "bFrameCount": {
          "type": "integer",
          "description": "The number of consecutive B-frames. Must be greater than or equal to zero. Must be less than `VideoStream.gop_frame_count` if set. The default is 0."
        },
        "aqStrength": {
          "type": "number",
          "description": "Specify the intensity of the adaptive quantizer (AQ). Must be between 0 and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A higher value equals a lower bitrate but smoother image. The default is 0."
        },
        "profile": {
          "type": "string",
          "description": "Enforces the specified codec profile. The following profiles are supported: *   8-bit profiles     *   `main` (default)     *   `main-intra`     *   `mainstillpicture` *   10-bit profiles     *   `main10` (default)     *   `main10-intra`     *   `main422-10`     *   `main422-10-intra`     *   `main444-10`     *   `main444-10-intra` *   12-bit profiles     *   `main12` (default)     *   `main12-intra`     *   `main422-12`     *   `main422-12-intra`     *   `main444-12`     *   `main444-12-intra` The available options are [FFmpeg-compatible](https://x265.readthedocs.io/). Note that certain values for this field may cause the transcoder to override other fields you set in the `H265CodecSettings` message."
        },
        "tune": {
          "type": "string",
          "description": "Enforces the specified codec tune. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265). Note that certain values for this field may cause the transcoder to override other fields you set in the `H265CodecSettings` message."
        },
        "preset": {
          "type": "string",
          "description": "Enforces the specified codec preset. The default is `veryfast`. The available options are [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265). Note that certain values for this field may cause the transcoder to override other fields you set in the `H265CodecSettings` message."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "H 265 Codec Settings",
      "description": "H265 codec settings."
    },
    "Vp9CodecSettings": {
      "properties": {
        "widthPixels": {
          "type": "integer",
          "description": "The width of the video in pixels. Must be an even integer. When not specified, the width is adjusted to match the specified height and input aspect ratio. If both are omitted, the input width is used. For portrait videos that contain horizontal ASR and rotation metadata, provide the width, in pixels, per the horizontal ASR. The API calculates the height per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "heightPixels": {
          "type": "integer",
          "description": "The height of the video in pixels. Must be an even integer. When not specified, the height is adjusted to match the specified width and input aspect ratio. If both are omitted, the input height is used. For portrait videos that contain horizontal ASR and rotation metadata, provide the height, in pixels, per the horizontal ASR. The API calculates the width per the horizontal ASR. The API detects any rotation metadata and swaps the requested height and width for the output."
        },
        "frameRate": {
          "type": "number",
          "description": "Required. The target video frame rate in frames per second (FPS). Must be less than or equal to 120. Will default to the input frame rate if larger than the input frame rate. The API will generate an output FPS that is divisible by the input FPS, and smaller or equal to the target FPS. See [Calculating frame rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for more information."
        },
        "bitrateBps": {
          "type": "integer",
          "description": "Required. The video bitrate in bits per second. The minimum value is 1,000. The maximum value is 480,000,000."
        },
        "pixelFormat": {
          "type": "string",
          "description": "Pixel format to use. The default is `yuv420p`. Supported pixel formats: - `yuv420p` pixel format - `yuv422p` pixel format - `yuv444p` pixel format - `yuv420p10` 10-bit HDR pixel format - `yuv422p10` 10-bit HDR pixel format - `yuv444p10` 10-bit HDR pixel format - `yuv420p12` 12-bit HDR pixel format - `yuv422p12` 12-bit HDR pixel format - `yuv444p12` 12-bit HDR pixel format"
        },
        "rateControlMode": {
          "type": "string",
          "description": "Specify the `rate_control_mode`. The default is `vbr`. Supported rate control modes: - `vbr` - variable bitrate"
        },
        "crfLevel": {
          "type": "integer",
          "description": "Target CRF level. Must be between 10 and 36, where 10 is the highest quality and 36 is the most efficient compression. The default is 21. **Note:** This field is not supported."
        },
        "gopFrameCount": {
          "type": "integer",
          "description": "Select the GOP size based on the specified frame count. Must be greater than zero."
        },
        "gopDuration": {
          "pattern": "^([0-9]+\\.?[0-9]*|\\.[0-9]+)s$",
          "type": "string",
          "description": "Select the GOP size based on the specified duration. The default is `3s`. Note that `gopDuration` must be less than or equal to [`segmentDuration`](#SegmentSettings), and [`segmentDuration`](#SegmentSettings) must be divisible by `gopDuration`.",
          "format": "regex"
        },
        "profile": {
          "type": "string",
          "description": "Enforces the specified codec profile. The following profiles are supported: *   `profile0` (default) *   `profile1` *   `profile2` *   `profile3` The available options are [WebM-compatible](https://www.webmproject.org/vp9/profiles/). Note that certain values for this field may cause the transcoder to override other fields you set in the `Vp9CodecSettings` message."
        }
      },
      "additionalProperties": true,
      "type": "object",
      "title": "Vp 9 Codec Settings",
      "description": "VP9 codec settings."
    }
  }
}